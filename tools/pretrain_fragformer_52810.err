
CondaError: Run 'conda init' before 'conda activate'

/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
INFO: Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
INFO: GPU available: True (cuda), used: True
INFO: TPU available: False, using: 0 TPU cores
INFO: IPU available: False, using: 0 IPUs
INFO: HPU available: False, using: 0 HPUs
wandb: Currently logged in as: ducogaillard. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/d.gaillard/projects/fragment_autoencoder/fragment_foundation_model/logs/pretrain_fragformer/runs/2024-04-23_23-32-54/wandb/run-20240423_233307-k416ofno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-meadow-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ducogaillard/lightning-hydra-template
wandb: üöÄ View run at https://wandb.ai/ducogaillard/lightning-hydra-template/runs/k416ofno
/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.
INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
INFO: SLURM auto-requeueing enabled. Setting signal handlers.
Error executing job with overrides: ['task_name=pretrain_fragformer']
Traceback (most recent call last):
  File "/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 402, in _check_dataloader_iterable
    iter(dataloader)  # type: ignore[call-overload]
TypeError: 'PretrainDataModule' object is not iterable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/d.gaillard/projects/fragment_autoencoder/fragment_foundation_model/tools/pretrain.py", line 35, in main
    return fragformer_entrypoint(config)
  File "/home/d.gaillard/projects/fragment_autoencoder/fragment_foundation_model/tools/../fragformer/entrypoints.py", line 115, in fragformer_entrypoint
    trainer.fit(model=model, datamodule=datamodule)
  File "/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 543, in fit
    call._call_and_handle_interrupt(
  File "/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 579, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 986, in _run
    results = self._run_stage()
  File "/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1032, in _run_stage
    self.fit_loop.run()
  File "/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 197, in run
    self.setup_data()
  File "/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 240, in setup_data
    _check_dataloader_iterable(dl, source, trainer_fn)
  File "/home/d.gaillard/source/miniconda3/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 407, in _check_dataloader_iterable
    raise TypeError(
TypeError: An invalid dataloader was passed to `Trainer.fit(train_dataloaders=...)`. Found <fragformer.datamodule.pretrain_datamodule.PretrainDataModule object at 0x7fa587df0730>.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: - 0.000 MB of 0.009 MB uploadedwandb: \ 0.000 MB of 0.009 MB uploadedwandb: | 0.000 MB of 0.009 MB uploadedwandb: / 0.000 MB of 0.009 MB uploadedwandb: - 0.000 MB of 0.009 MB uploadedwandb: \ 0.000 MB of 0.009 MB uploadedwandb: | 0.009 MB of 0.009 MB uploadedwandb: / 0.009 MB of 0.009 MB uploadedwandb: - 0.009 MB of 0.009 MB uploadedwandb: \ 0.009 MB of 0.009 MB uploadedwandb: | 0.009 MB of 0.009 MB uploadedwandb: / 0.009 MB of 0.009 MB uploadedwandb: - 0.009 MB of 0.009 MB uploadedwandb: \ 0.009 MB of 0.009 MB uploadedwandb: | 0.009 MB of 0.009 MB uploadedwandb: / 0.019 MB of 0.055 MB uploadedwandb: - 0.055 MB of 0.055 MB uploadedwandb: \ 0.055 MB of 0.055 MB uploadedwandb: | 0.055 MB of 0.055 MB uploadedwandb: üöÄ View run true-meadow-2 at: https://wandb.ai/ducogaillard/lightning-hydra-template/runs/k416ofno
wandb: Ô∏è‚ö° View job at https://wandb.ai/ducogaillard/lightning-hydra-template/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE2NTkyMzA0MQ==/version_details/v0
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: /home/d.gaillard/projects/fragment_autoencoder/fragment_foundation_model/logs/pretrain_fragformer/runs/2024-04-23_23-32-54/wandb/run-20240423_233307-k416ofno/logs
srun: error: boveri: task 0: Exited with exit code 1
