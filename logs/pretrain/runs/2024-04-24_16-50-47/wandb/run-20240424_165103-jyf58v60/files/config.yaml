wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.10.14
    cli_version: 0.16.6
    framework: huggingface
    huggingface_version: 4.27.4
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1713970263.0
    t:
      1:
      - 1
      - 9
      - 11
      - 41
      - 49
      - 50
      - 55
      - 103
      - 105
      2:
      - 1
      - 9
      - 11
      - 41
      - 49
      - 50
      - 55
      - 103
      - 105
      3:
      - 7
      - 23
      4: 3.10.14
      5: 0.16.6
      6: 4.27.4
      8:
      - 5
      13: linux-x86_64
    m:
    - 1: trainer/global_step
      6:
      - 3
    - 1: lr-AdamW
      5: 1
      6:
      - 1
model:
  desc: null
  value: '{''_target_'': ''fragformer.models.fragment_xtransformer.FragmentXTransformer'',
    ''num_tokens'': 9, ''attn_layers'': {''_target_'': ''x_transformers.x_transformers.Encoder'',
    ''dim'': 128, ''depth'': 2, ''heads'': 2, ''ff_glu'': True, ''attn_dropout'':
    0.1, ''ff_dropout'': 0.1}}'
model/params/total:
  desc: null
  value: 542720
model/params/trainable:
  desc: null
  value: 542720
model/params/non_trainable:
  desc: null
  value: 0
datamodule:
  desc: null
  value: '{''_target_'': ''fragformer.datamodule.pretrain_datamodule.PretrainDataModule'',
    ''parquet_path'': ''${oc.env:PARQUET_PATH}'', ''columns'': [''read1_seq'', ''read2_seq''],
    ''context_window'': 25, ''tokenizer'': {''_target_'': ''fragformer.datamodule.components.tokenizers.BasicTokenizer'',
    ''vocabulary'': ''ACGT'', ''add_special_tokens'': True}, ''transform'': None,
    ''batch_size'': 2048, ''num_workers'': 0, ''pin_memory'': True}'
trainer:
  desc: null
  value: '{''_target_'': ''lightning.pytorch.Trainer'', ''accelerator'': ''gpu'',
    ''devices'': 1, ''max_epochs'': 500, ''log_every_n_steps'': 1}'
seed:
  desc: null
  value: 42
callbacks:
  desc: null
  value: '{''model_checkpoint'': {''_target_'': ''lightning.pytorch.callbacks.ModelCheckpoint'',
    ''dirpath'': ''${oc.env:CHECKPOINT_PATH}pretrain'', ''filename'': ''pretrain_checkpoint_{epoch:02d}-{train_loss_epoch:.3f}'',
    ''monitor'': ''train_loss'', ''verbose'': False, ''save_last'': True, ''save_top_k'':
    5, ''mode'': ''min'', ''auto_insert_metric_name'': True, ''save_weights_only'':
    False, ''every_n_train_steps'': None, ''train_time_interval'': None, ''every_n_epochs'':
    1, ''save_on_train_epoch_end'': True}, ''lr_monitor'': {''_target_'': ''lightning.pytorch.callbacks.LearningRateMonitor''},
    ''rich_progress_bar'': {''_target_'': ''lightning.pytorch.callbacks.RichProgressBar''},
    ''model_summary'': {''_target_'': ''lightning.pytorch.callbacks.RichModelSummary'',
    ''max_depth'': 1}}'
optimizer:
  desc: null
  value: null
transforms:
  desc: null
  value: '{''fit'': <fragformer.transforms.transforms.TransformFactory object at 0x7f7339bb9a80>}'
loss:
  desc: null
  value: null
scheduler:
  desc: null
  value: null
parquet_path:
  desc: null
  value: /processing/d.gaillard/top1_mal_full_fragments/PGDX25828P_WGS_hg19_mrk_25length_fragment_end_motifs_shuffled.parquet
columns:
  desc: null
  value:
  - read1_seq
  - read2_seq
context_window:
  desc: null
  value: 25
tokenizer:
  desc: null
  value: <fragformer.datamodule.components.tokenizers.BasicTokenizer object at 0x7f7336daa230>
transform:
  desc: null
  value: null
padder:
  desc: null
  value: null
batch_size:
  desc: null
  value: 2048
num_workers:
  desc: null
  value: 0
pin_memory:
  desc: null
  value: true
